{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib  # For loading the saved model\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import threading\n",
    "\n",
    "# Initialize Flask application\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the trained model\n",
    "model = joblib.load('model_pickle.pkl')  # Ensure your model is saved as a pickle file\n",
    "\n",
    "# Sample user input data\n",
    "user_input_data = {\n",
    "    'Time': [3000],\n",
    "    'V1': [1.2],\n",
    "    'V2': [-0.5],\n",
    "    'V3': [1.3],\n",
    "    'V4': [-0.3],\n",
    "    'V5': [0.8],\n",
    "    'V6': [-1.1],\n",
    "    'V7': [1.5],\n",
    "    'V8': [-0.7],\n",
    "    'V9': [0.4],\n",
    "    'V10': [0.9],\n",
    "    'V11': [-1.4],\n",
    "    'V12': [0.6],\n",
    "    'V13': [-0.1],\n",
    "    'V14': [1.0],\n",
    "    'V15': [0.5],\n",
    "    'V16': [-0.3],\n",
    "    'V17': [1.1],\n",
    "    'V18': [-0.9],\n",
    "    'V19': [0.3],\n",
    "    'V20': [1.2],\n",
    "    'V21': [-0.6],\n",
    "    'V22': [0.7],\n",
    "    'V23': [-1.2],\n",
    "    'V24': [0.4],\n",
    "    'V25': [0.1],\n",
    "    'V26': [-0.8],\n",
    "    'V27': [0.6],\n",
    "    'V28': [-1.0],\n",
    "    'Amount': [200]\n",
    "}\n",
    "\n",
    "# Define route for prediction\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    # Convert user input data to DataFrame\n",
    "    user_input_df = pd.DataFrame(user_input_data)\n",
    "\n",
    "    # Prepare DMatrix for user input\n",
    "    duser_input = xgb.DMatrix(user_input_df)\n",
    "\n",
    "    # Predict using the trained model\n",
    "    user_input_preds = model.predict(duser_input)\n",
    "\n",
    "    # Determine if the transaction is fraud or not fraud\n",
    "    prediction = 'fraud' if user_input_preds[0] == 1 else 'not fraud'\n",
    "\n",
    "    # Return the prediction\n",
    "    return jsonify({'prediction': prediction, 'probability': float(user_input_preds[0])})\n",
    "\n",
    "# Function to run the Flask app\n",
    "def run_app():\n",
    "    app.run(port=5002)  # Specify a different port to avoid conflicts\n",
    "\n",
    "# Run the Flask app in a separate thread\n",
    "thread = threading.Thread(target=run_app)\n",
    "thread.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': 'not fraud', 'probability': 0.0007646139711141586}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Define the URL for the prediction endpoint\n",
    "url = 'http://127.0.0.1:5002/predict'\n",
    "\n",
    "# Create a test case with higher probability of being fraudulent\n",
    "user_input_data = {\n",
    "    'Time': [3500],  # Randomly chosen\n",
    "    'V1': [5.2],    # Modify as needed\n",
    "    'V2': [-5.5],   # Modify as needed\n",
    "    'V3': [1.3],    # Modify as needed\n",
    "    'V4': [-0.3],   # Modify as needed\n",
    "    'V5': [-9.8],    # Modify as needed\n",
    "    'V6': [-1.1],   # Modify as needed\n",
    "    'V7': [9.5],    # Modify as needed\n",
    "    'V8': [-0.7],   # Modify as needed\n",
    "    'V9': [0],    # Modify as needed\n",
    "    'V10': [0.9],   # Modify as needed\n",
    "    'V11': [1.4],   # Set high value indicative of fraud\n",
    "    'V12': [1.6],   # Set high value indicative of fraud\n",
    "    'V13': [-5.123],  # Modify as needed\n",
    "    'V14': [1.7],   # Set high value indicative of fraud\n",
    "    'V15': [0.5],   # Modify as needed\n",
    "    'V16': [-20.3],  # Modify as needed\n",
    "    'V17': [3.9],   # Set high value indicative of fraud\n",
    "    'V18': [-3.9],  # Modify as needed\n",
    "    'V19': [88888.3],   # Modify as needed\n",
    "    'V20': [99.2],   # Modify as needed\n",
    "    'V21': [-3.6],  # Modify as needed\n",
    "    'V22': [3.7],   # Modify as needed                                        \n",
    "    'V23': [-1.2],  # Modify as needed\n",
    "    'V24': [3.4],   # Modify as needed\n",
    "    'V25': [9.01],   # Modify as needed\n",
    "    'V26': [-20.8],  # Modify as needed\n",
    "    'V27': [9.6],   # Modify as needed\n",
    "    'V28': [-5.0],  # Modify as needed\n",
    "    'Amount': [20000000] # Modify as needed\n",
    "}\n",
    "\n",
    "# Make the POST request to the endpoint with the high-risk input data\n",
    "response = requests.post(url, json=user_input_data)\n",
    "\n",
    "# Print the response\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': 0.00010690204362617806}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      " * Restarting with stat\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/paniz/Documents/GitHub/shark-tanked/venv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/paniz/Documents/GitHub/shark-tanked/venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 1074, in launch_instance\n",
      "    app.initialize(argv)\n",
      "  File \"/Users/paniz/Documents/GitHub/shark-tanked/venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 118, in inner\n",
      "    return method(app, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/paniz/Documents/GitHub/shark-tanked/venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 692, in initialize\n",
      "    self.init_sockets()\n",
      "  File \"/Users/paniz/Documents/GitHub/shark-tanked/venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 331, in init_sockets\n",
      "    self.shell_port = self._bind_socket(self.shell_socket, self.shell_port)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/paniz/Documents/GitHub/shark-tanked/venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 253, in _bind_socket\n",
      "    return self._try_bind_socket(s, port)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/paniz/Documents/GitHub/shark-tanked/venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 229, in _try_bind_socket\n",
      "    s.bind(\"tcp://%s:%i\" % (self.ip, port))\n",
      "  File \"/Users/paniz/Documents/GitHub/shark-tanked/venv/lib/python3.11/site-packages/zmq/sugar/socket.py\", line 311, in bind\n",
      "    super().bind(addr)\n",
      "  File \"_zmq.py\", line 898, in zmq.backend.cython._zmq.Socket.bind\n",
      "  File \"_zmq.py\", line 160, in zmq.backend.cython._zmq._check_rc\n",
      "zmq.error.ZMQError: Address already in use (addr='tcp://127.0.0.1:9012')\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paniz/Documents/GitHub/shark-tanked/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "\n",
    "# Initialize Flask application\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the trained model\n",
    "model = joblib.load('model_pickle.pkl')  # Assuming your model is saved as a pickle file\n",
    "\n",
    "# Define the feature names (predictors)\n",
    "predictors = ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
    "              'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
    "              'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    # Get JSON data from the request\n",
    "    user_input_data = request.json\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    user_input_df = pd.DataFrame(user_input_data)\n",
    "\n",
    "    # Prepare DMatrix for user input\n",
    "    duser_input = xgb.DMatrix(user_input_df[predictors])\n",
    "\n",
    "    # Predict using the trained model\n",
    "    user_input_preds = model.predict(duser_input)\n",
    "\n",
    "    # Return the prediction as JSON\n",
    "    return jsonify({'prediction': user_input_preds.tolist()})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'app' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Define the prediction endpoint\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;129m@app\u001b[39m\u001b[38;5;241m.\u001b[39mroute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/predict\u001b[39m\u001b[38;5;124m'\u001b[39m, methods\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m():\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m         transaction \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mjson\n",
      "\u001b[0;31mNameError\u001b[0m: name 'app' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the prediction endpoint\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        transaction = request.json\n",
    "        processed_transaction = preprocess_transaction(transaction)\n",
    "        prediction = model.predict(processed_transaction)\n",
    "        # Assuming model outputs 1 for fraud and 0 for non-fraud\n",
    "        result = 'Fraud' if prediction[0] == 1 else 'Non-Fraud'\n",
    "        return jsonify({'prediction': result})\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)})\n",
    "\n",
    "# Run the Flask application\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
